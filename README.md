# AI-Powered Explainable Credit Card Fraud Detection
### ğŸ” XGBoost â€¢ SHAP â€¢ SMOTE â€¢ PCA Dataset â€¢ Web App
A complete end-to-end machine learning system that detects fraudulent credit card transactions with AI explainability.<br>
Built using XGBoost, interpreted with SHAP, balanced with SMOTE, and deployed as a web application for easy use.

## ğŸš€ Project Overview
This project identifies fraudulent credit card transactions using an AI model and explains why a transaction was marked as fraud.<br>
Since fraud detection is a high-risk domain, adding Explainable AI (XAI) increases trust, transparency, and accountability.

## ğŸ“‚ Dataset
We used the Credit Card Fraud Detection Dataset from Kaggle.<br>
Key points:<br>
â— Contains real European credit card transactions<br>
â— Heavily imbalanced (fraud < 1%)<br>
â— Features V1â€“V28 are PCA-transformed for confidentiality<br>
â— Class is the target variable<br>
    - 0 â†’ Legitimate<br>
    - 1 â†’ Fraud<br>

## ğŸ§¹ Data Preprocessing

â— Dropped the Time feature (not useful for prediction)<br>
â— Standardized the Amount feature using StandardScaler to match PCA feature scales<br>
â— Performed EDA to understand fraud distribution and feature patterns<br>
â— Applied SMOTE to handle severe class imbalance<br>
â— Split the data into training and testing sets<br>

## ğŸ¤– Model Used: XGBoost

We chose XGBoost because it:<br>
â— Handles imbalanced classes well<br>
â— Works great with tabular data<br>
â— Captures complex, non-linear patterns<br>
â— Gives high accuracy and AUC scores

## ğŸ” Explainability: SHAP

To avoid â€œblack-boxâ€ predictions, we integrated SHAP (SHapley Additive exPlanations).<br>

SHAP provides:<br>
â— Feature contribution for each prediction<br>
â— Global and local interpretability<br>
â— Visual plots explaining why a transaction was flagged<br>

## ğŸ“Š Evaluation Metrics

The model was evaluated using:<br>
Accuracy (99.5%)<br>
Precision (91%), Recall(82%), F1-score<br>
ROC-AUC<br>
Confusion Matrix<br>

Because of class imbalance, AUC and Recall were prioritized.

## ğŸ› ï¸ Tech Stack<br>

â— Python<br>
â— Pandas, NumPy<br>
â— XGBoost<br>
â— Scikit-learn<br>
â— SHAP<br>
â— Imbalanced-Learn (SMOTE)<br>

## ğŸ‘¥ Team Contribution Note

This project was completed as a team effort. I personally handled the data preparation workflow, including data collection, preprocessing, dropping irrelevant attributes, SMOTE for balancing, feature scaling and the entire EDA process. The web integration and deployment module is currently in progress as part of the ongoing collaborative development.
